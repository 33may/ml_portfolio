{
 "cells": [
  {
   "cell_type": "code",
   "id": "d97722ef4fcf9857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:45:02.006861Z",
     "start_time": "2025-05-20T23:44:58.310120Z"
    }
   },
   "source": [
    "import torch\n",
    "from robotics.model_src.dataset import PushTDataset\n",
    "from robotics.model_src.diffusion_model import ConditionalUnet1D\n",
    "from robotics.model_src.visual_encoder import CLIPVisualEncoder"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/may33/miniconda3/envs/diffusion/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/may33/miniconda3/envs/diffusion/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:45:02.074465Z",
     "start_time": "2025-05-20T23:45:02.010194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "247be12746aaf133",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T23:45:06.840317Z",
     "start_time": "2025-05-20T23:45:03.961493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "pred_horizon = 16\n",
    "obs_horizon = 2\n",
    "action_horizon = 8\n",
    "\n",
    "# create dataset from file\n",
    "dataset = PushTDataset(\n",
    "    data_path=\"../data/demonstrations_snapshot_1.zarr\",\n",
    "    obs_horizon=obs_horizon,\n",
    "    prediction_horizon=pred_horizon\n",
    ")\n",
    "\n",
    "# create dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    # accelerate cpu-gpu transfer\n",
    "    pin_memory=True,\n",
    "    # don't kill worker process after each epoch\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# visualize data in batch\n",
    "batch = next(iter(dataloader))\n",
    "print(\"batch['img_obs'].shape:\", batch['img_obs'].shape)\n",
    "print(\"batch['act_obs'].shape:\", batch['act_obs'].shape)\n",
    "print(\"batch['act_pred'].shape\", batch['act_pred'].shape)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 88741.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch['img_obs'].shape: torch.Size([64, 3, 224, 224, 3])\n",
      "batch['act_obs'].shape: torch.Size([64, 3, 2])\n",
      "batch['act_pred'].shape torch.Size([64, 16, 2])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:45:08.022567Z",
     "start_time": "2025-05-20T23:45:07.996601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image = torch.Tensor(dataset[0][\"img_obs\"][None, :, :, :, :]).to(device)\n",
    "act_obs = torch.Tensor(dataset[0][\"act_obs\"][None, :, :]).to(device)"
   ],
   "id": "4f7e8070c15d9926",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:45:10.459448Z",
     "start_time": "2025-05-20T23:45:08.659310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "visual_encoder = CLIPVisualEncoder().to(device)\n",
    "\n",
    "vision_feature_dim = visual_encoder.get_output_shape()\n",
    "\n",
    "action_observation_dim = 2\n",
    "\n",
    "obs_dim = vision_feature_dim + action_observation_dim\n",
    "\n",
    "action_dim = 2\n",
    "\n",
    "noise_prediction_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim * (obs_horizon + 1),\n",
    ").to(device)"
   ],
   "id": "f7d7b4313d91eca7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 8.731597e+07\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T23:45:52.648735Z",
     "start_time": "2025-05-20T23:45:52.603278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    image_features = visual_encoder.encode(image.flatten(start_dim=0, end_dim=1))\n",
    "\n",
    "    image_features = image_features.reshape(*image.shape[:2], -1)\n",
    "\n",
    "    obs = torch.cat([image_features, act_obs], dim=-1)\n",
    "\n",
    "    noised_action = torch.randn((1, pred_horizon, action_dim)).to(device)\n",
    "\n",
    "    timestep_tensor = torch.randint(0, 101, (1,), device=device)\n",
    "\n",
    "    noise = noise_prediction_net(\n",
    "        sample=noised_action,\n",
    "        timestep=timestep_tensor,\n",
    "        global_cond=obs.flatten(start_dim=1)\n",
    "    )\n",
    "\n",
    "    denoised_action = noised_action - noise\n"
   ],
   "id": "d65b3c308b220a5b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "17fba7cfa53aacd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
