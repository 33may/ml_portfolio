{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "550ac9fd2842a69b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-03T23:53:05.338459Z",
     "start_time": "2025-06-03T23:53:05.292542Z"
    }
   },
   "source": [
    "import h5py\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:53:05.341891Z",
     "start_time": "2025-06-03T23:53:05.340434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"../data/robot_demonstrations/RoboTurkPilot/pegs-full\"\n",
    "\n",
    "# f = h5py.File(\"../data/robot_demonstrations/RoboTurkPilot/pegs-full\", \"r\")"
   ],
   "id": "196004755aacf077",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T11:31:58.153267Z",
     "start_time": "2025-06-04T11:31:58.141630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ─── зависимости ──────────────────────────────────────────\n",
    "import os, json, hashlib, collections, h5py, numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm                    # ✓ прогресс-бар\n",
    "import robosuite as rs\n",
    "from robosuite.environments.base import MujocoEnv\n",
    "# ───────────────────────────────────────────────────────────\n",
    "\n",
    "def xml_md5(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "# ==========================================================\n",
    "#                     ENV-КЭШ\n",
    "# ==========================================================\n",
    "class EnvCache:\n",
    "    def __init__(self, task_name: str, models_dir: str | None,\n",
    "                 cam_name=\"agentview\", img_size=128,\n",
    "                 default=True, max_envs=None, render=False):\n",
    "\n",
    "        self.task   = task_name\n",
    "        self.models = models_dir\n",
    "        self.cam    = cam_name\n",
    "        self.size   = img_size\n",
    "        self.render = render\n",
    "        self.deflt  = default\n",
    "        self.maxN   = max_envs or 32\n",
    "\n",
    "        self._one : MujocoEnv | None = None\n",
    "        self._lru : \"collections.OrderedDict[str, MujocoEnv]\" = collections.OrderedDict()\n",
    "        self._has_xml = \"mujoco_model_path\" in rs.environments.base.make.__code__.co_varnames\n",
    "\n",
    "    def _new_env(self, xml: str | None = None) -> MujocoEnv:\n",
    "        kw = dict(\n",
    "            env_name               = self.task,\n",
    "            robots                 = \"Sawyer\",\n",
    "            has_renderer           = self.render,\n",
    "            has_offscreen_renderer = True,      # ← ВСЕГДА TRUE!\n",
    "            use_camera_obs         = True,\n",
    "            camera_names           = [self.cam],\n",
    "            camera_heights         = self.size,\n",
    "            camera_widths          = self.size,\n",
    "        )\n",
    "        if xml and self._has_xml:\n",
    "            kw[\"mujoco_model_path\"] = xml\n",
    "        return rs.make(**kw)\n",
    "\n",
    "    def get_env(self, xml_file: str | None = None) -> MujocoEnv:\n",
    "        if self.deflt or not xml_file:\n",
    "            if self._one is None:\n",
    "                self._one = self._new_env()\n",
    "            return self._one\n",
    "\n",
    "        path = os.path.join(self.models, xml_file)\n",
    "        key  = xml_md5(path)\n",
    "        if key in self._lru:                       # hit\n",
    "            self._lru.move_to_end(key)\n",
    "            return self._lru[key]\n",
    "\n",
    "        env = self._new_env(path)                  # miss → создать\n",
    "        self._lru[key] = env; self._lru.move_to_end(key)\n",
    "        if len(self._lru) > self.maxN:             # LRU-ограничение\n",
    "            _, old = self._lru.popitem(last=False)\n",
    "            old.close()\n",
    "        return env\n",
    "\n",
    "# ==========================================================\n",
    "#                  DATASET + РЕНДЕР\n",
    "# ==========================================================\n",
    "class SawyerDataset(Dataset):\n",
    "    def __init__(self, data_path, horizon_left=2, horizon_right=8,\n",
    "                 image_size=128, camera_name=\"agentview\",\n",
    "                 img_batch=4096, limit_demo=None):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.img_size   = image_size\n",
    "        self.camera     = camera_name\n",
    "        self.device     = torch.device(\"cuda\")\n",
    "\n",
    "        f = h5py.File(os.path.join(data_path, \"demo.hdf5\"), \"r\")\n",
    "        grp = f[\"data\"]\n",
    "        self.task = grp.attrs[\"env\"].replace(\"Sawyer\", \"\")\n",
    "        demos = list(grp.keys())[:limit_demo] if limit_demo else list(grp.keys())\n",
    "\n",
    "        # ── собираем все массивы ────────────────────────────\n",
    "        idx, states, vel, grip, xmls, ends = [], [], [], [], [], [0]\n",
    "        for d in demos:\n",
    "            g  = grp[d]\n",
    "            st = g[\"states\"][:]\n",
    "            n  = len(st)\n",
    "            win = np.clip(np.arange(n-1)[:,None] + np.arange(-horizon_left, horizon_right+1), 0, n-1)\n",
    "            idx.append(win + ends[-1])\n",
    "            states.append(st)\n",
    "            vel.append(g[\"joint_velocities\"][:])\n",
    "            grip.append(g[\"gripper_actuations\"][:])\n",
    "            xmls.extend([g.attrs[\"model_file\"]]*n)\n",
    "            ends.append(ends[-1]+n)\n",
    "\n",
    "        self.idx   = np.concatenate(idx)\n",
    "        self.state = np.concatenate(states)\n",
    "        self.vel   = np.concatenate(vel)\n",
    "        self.grip  = np.concatenate(grip)\n",
    "        self.xmls  = np.array(xmls)\n",
    "\n",
    "        # ── off-screen кэш ─────────────────────────────────\n",
    "        self.ecache = EnvCache(self.task,\n",
    "                               models_dir=os.path.join(data_path,\"models\"),\n",
    "                               cam_name=self.camera,\n",
    "                               img_size=image_size,\n",
    "                               default=True,        # можно False, если нужен XML\n",
    "                               render=False)\n",
    "\n",
    "        # ── memmap для RGB ────────────────────────────────\n",
    "        self.img_dir  = os.path.join(data_path, f\"images_{camera_name}_{image_size}\")\n",
    "        self.img_bin  = os.path.join(self.img_dir, \"images.dat\")\n",
    "        self.meta_js  = os.path.join(self.img_dir, \"images.meta\")\n",
    "        os.makedirs(self.img_dir, exist_ok=True)\n",
    "\n",
    "        if not (os.path.isfile(self.img_bin) and os.path.isfile(self.meta_js)):\n",
    "            self._render_and_store(batch=img_batch)\n",
    "\n",
    "        with open(self.meta_js) as fp:\n",
    "            meta = json.load(fp)\n",
    "        N,H,W = meta[\"N\"], meta[\"H\"], meta[\"W\"]\n",
    "        self.img_mm = np.memmap(self.img_bin, mode=\"r\", dtype=np.uint8,\n",
    "                                shape=(N,H,W,3))\n",
    "\n",
    "    # ───────────────────────────────────────────────────────\n",
    "    def _render_and_store(self, batch: int):\n",
    "        N,H,W = len(self.state), self.img_size, self.img_size\n",
    "        img_mm = np.memmap(self.img_bin, mode=\"w+\", dtype=np.uint8,\n",
    "                           shape=(N,H,W,3))\n",
    "\n",
    "        for start in tqdm(range(0, N, batch), desc=\"render\", unit=\"img\"):\n",
    "            for i in range(start, min(start+batch, N)):\n",
    "                env = self.ecache.get_env(self.xmls[i])\n",
    "                env.sim.set_state_from_flattened(self.state[i])\n",
    "                env.sim.forward()\n",
    "                bgr = env.sim.render(width=W, height=H, camera_name=self.camera)\n",
    "                img_mm[i] = bgr[..., ::-1]            # BGR→RGB\n",
    "\n",
    "        img_mm.flush()\n",
    "        json.dump({\"N\":N,\"H\":H,\"W\":W}, open(self.meta_js,\"w\"))\n",
    "        print(f\"RGB-кадры сохранены в {self.img_bin}\")\n",
    "\n",
    "    # ── pytorch API ────────────────────────────────────────\n",
    "    def __len__(self):  return len(self.idx)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        w  = self.idx[i]\n",
    "        c  = w[len(w)//2]\n",
    "        img = torch.from_numpy(self.img_mm[c]).permute(2,0,1).float()/255.\n",
    "        state  = torch.tensor(self.state[c], dtype=torch.float32)\n",
    "        action = torch.tensor(self.vel[c], dtype=torch.float32)\n",
    "        return {\"pixels\": img.to(self.device),\n",
    "                \"state\" : state.to(self.device),\n",
    "                \"action\": action.to(self.device)}\n"
   ],
   "id": "9bc10a9376ff8030",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T11:31:58.646528Z",
     "start_time": "2025-06-04T11:31:58.627485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = SawyerDataset(data_path=data_path,\n",
    "                   horizon_left=2, horizon_right=8,\n",
    "                   limit_demo=5)           # первый запуск — появится tqdm\n",
    "sample = ds[0]\n",
    "print(sample[\"pixels\"].shape, sample[\"state\"].shape, sample[\"action\"].shape)"
   ],
   "id": "18a8c5c48303b8a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128]) torch.Size([47]) torch.Size([7])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b771ad4557bf26a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
