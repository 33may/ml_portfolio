{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convolution on GPU\n",
    "\n",
    "Modern machine learning is deeply intertwined with the concept of GPU computations. However, a GPU is not a magic button that automatically speeds up every operation. To fully harness the benefits of modern GPUs, algorithms must be carefully designed to run smoothly on these parallel architectures, leveraging concepts such as SIMD (Single Instruction, Multiple Data) along with other optimization techniques.\n",
    "\n",
    "In this notebook, I will dive into the details of how to implement a convolution operation an essential component of convolution layersâ€”specifically tailored to work efficiently on the GPU.\n",
    "\n",
    "This work will include theory, code and evaluation of the algorithm. For the implementation I will use numpy and cupy as the main tool, and also I will research on the numba tool and evaluate the ways to optimize the algorithm even further."
   ],
   "id": "2284c107c003e548"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T18:48:51.728956Z",
     "start_time": "2025-03-10T18:48:51.497746Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from numba import njit"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic Convolution Algorithm\n",
    "\n",
    "In the introductory lectures to the Convolutional Neural Networks, the most basic algorithm is introduced: it slides over each patch along the $i$ and $j$ axes and accumulates the result of the matrix multiplication between the input patch and the convolution kernel. In mathematical terms, for a single chanel of input $I$ and kernel $K$, the output at position $(i,j)$ is computed as:\n",
    "\n",
    "$$\n",
    "O(i,j) = \\sum_{m=0}^{k_h-1} \\sum_{n=0}^{k_w-1} I(i:i+m, j:j+n) \\cdot K(m,n)\n",
    "$$"
   ],
   "id": "7870a4f02797146d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:48:52.149933Z",
     "start_time": "2025-03-10T18:48:52.146042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(self, X):\n",
    "    # get shape of the input tensor\n",
    "    batch_size, height, width, in_channels = X.shape\n",
    "    # compute shape of output tensor\n",
    "    out_height = height - self.filter_size + 1 + 2 * self.padding\n",
    "    out_width = width - self.filter_size + 1 + 2 * self.padding\n",
    "    # save last input for backward pass\n",
    "    self.last_X = X\n",
    "    # create zeros tensor for result\n",
    "    result = np.zeros((batch_size, out_height, out_width, self.out_channels))\n",
    "    # reshape weights to use matrix multiplication trick\n",
    "    weights = self.W.value.reshape(self.in_channels * self.filter_size * self.filter_size, self.out_channels)\n",
    "    # iterate each pixel in output tensor\n",
    "    for y in range(out_height):\n",
    "        for x in range(out_width):\n",
    "            # take the perception widow of the output pixel\n",
    "            patch = X[:, y:y + self.filter_size, x:x + self.filter_size, :]\n",
    "            # unwrap patch to use matrix multiplication trick\n",
    "            patch_flat = patch.reshape(batch_size, self.in_channels * self.filter_size * self.filter_size)\n",
    "            # convolution operation\n",
    "            res = patch_flat @ weights + self.B.value\n",
    "            # add pixels to result tensor\n",
    "            result[:, y, x, :] = res\n",
    "    return result"
   ],
   "id": "332cb8df9d307776",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "While this approach is conceptually simple and useful to understand the idea of convolution, it has several limitations:\n",
    "\n",
    "1. **Inefficient Looping Structure:**\n",
    "   The basic algorithm uses nested loops to traverse the input chanel, resulting in $O(H \\times W \\times k_h \\times k_w)$ time complexity. This becomes computationally expensive as the input size or the kernel dimensions increase.\n",
    "\n",
    "2. **Poor Memory Access Patterns:**\n",
    "   Iterating patch-by-patch can lead to inefficient memory access, as data may not be loaded into the cache optimally. This results in significant overhead, especially when running on architectures where memory bandwidth is a critical bottleneck.\n",
    "\n",
    "3. **Limited Parallelism:**\n",
    "   GPUs thrive on parallel processing, but the naive implementation with its serial loop structure fails to exploit the inherent parallelism. The lack of vectorized operations means that the GPU's SIMD (Single Instruction, Multiple Data) capabilities remain underutilized.\n",
    "\n",
    "These challenges motivate the need for optimized approaches that reorganize computations and memory access patterns, allowing us to fully harness the power of GPU acceleration for convolution operations."
   ],
   "id": "89033405360f07e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Convolution on GPU Algorithm\n",
    "\n",
    "To start developing the algorithm, it is essential to clearly structure and understand all the input data:\n",
    "\n",
    "- **Input Tensor ($I$)**: with shape $(batch\\_size \\times filter\\_size \\times filter\\_size \\times in\\_channels)$.\n",
    "- **Weights Tensor ($W$)**: with shape $(filter\\_size \\times filter\\_size \\times in\\_channels \\times out\\_channels)$.\n",
    "- **Bias Tensor ($b$)**: with shape $(filter\\_size \\times filter\\_size \\times in\\_channels \\times out\\_channels)$.\n",
    "\n",
    "In introductory lectures on convolution operations, the most basic algorithm slides a kernel over each patch along the $i$ and $j$ axes, performing an element-wise multiplication of the patch and the weights, then summing the result to produce the output. The core issue with this basic approach is that each convolution operation is executed separately on small data patches (of size $filter\\_size \\times filter\\_size$) using implicit iteration loops.\n",
    "\n",
    "Our goal is to transform these isolated operations into a vectorized form. The approach taken here represents the entire convolution over the whole image as a single matrix multiplication. To achieve this, I introduce the `im2conv_matrix` operation, which effectively reshapes and aggregates the convolution patches into a form amenable to efficient, parallel computation on the GPU."
   ],
   "id": "7dda1b8ef9184872"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### im2conv_matrix\n",
    "\n",
    "The idea behind this operation is to transform the input tensor into a single matrix with the following shape:\n",
    "$$\n",
    "(batch\\_size \\cdot H\\_out \\cdot W\\_out \\times filter \\cdot filter \\cdot in\\_channels)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $W\\_out$ represents the total number of patches along the width.\n",
    "- $H\\_out$ represents the total number of patches along the height.\n",
    "\n",
    "In this configuration, each row corresponds to a flattened patch extracted from the input tensor, encompassing all channels.\n",
    "\n",
    "Next, we reshape the weights tensor to have the shape:\n",
    "$$\n",
    "(out\\_channels \\times filter \\cdot filter \\cdot in\\_channels)\n",
    "$$\n",
    "This reshaping organizes the filters such that each row now represents a complete set of filter weights for all input channels corresponding to a specific output channel. With this setup, we can perform the convolution operation as a single matrix multiplication, which is highly efficient on the GPU.\n",
    "\n",
    "Then the result of Convolution operation could be done as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&result = input\\_reshaped \\cdot weights^T \\\\\n",
    "&\\text{with shape } result (batch\\_size \\cdot H\\_out \\cdot W\\_out \\times out\\_channels)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "### im2conv_matrix logic\n",
    "\n",
    "Suppose input is tensor, without batching with 2 channels, then the result of the `im2conv_matrix` operation should look like:\n",
    "\n",
    "<img src=\"imgs/conv_matrix.jpg\">\n",
    "\n",
    "so every row in the `im2conv_matrix` is single conv operation.\n",
    "\n",
    "The approach to achieve that structured below:\n",
    "\n",
    "#### Approach:\n",
    "\n",
    "1. Create arrays representing starting indices of each patch along $x$ and $y$ axes:\n",
    "\n",
    "```python\n",
    "x_start = np.arange(0, h - filter, stride)\n",
    "y_start = np.arange(0, w - filter, stride)  # similarly for y-axis\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "2. Next, from these starting indices along each axis, we create a mesh-grid matrix. This allows us to identify the starting indices of each patch along both height and width dimensions for every output position:\n",
    "\n",
    "```text\n",
    "y_starts, x_starts = np.meshgrid(x_start, y_start, indexing='ij')\n",
    "y_starts: [H_out, W_out]\n",
    "x_starts: [H_out, W_out]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "3. After that, we need to add the ability to traverse each patch. Doing so allows us to get indices of each element within each patch.\n",
    "\n",
    "```python\n",
    "dy, dx = np.mgrid[0:filter, 0:filter]\n",
    "\n",
    "# indices of each element within the patch along two axes:\n",
    "y_indices = y_starts[:, :, None, None] + dy\n",
    "x_indices = x_starts[:, :, None, None] + dx\n",
    "# Resulting shape: [H_out, W_out, filter, filter]\n",
    "\n",
    "# This matrix stores (i, j) indices for each element in every convolutional patch.\n",
    "```\n",
    "\n",
    "4. Using the results from step 3, we now have the ability to get indices of any input element. The remaining step is straightforward:\n",
    "\n",
    "We want to use advanced indexing to transform the input $X$ into our desired format.\n",
    "\n",
    "```python\n",
    "batch_idx = np.arange(batch)[:, None, None, None]\n",
    "channel_idx = np.arange(channels)[None, None, None, :]\n",
    "\n",
    "# reshape is done so broadcasting correctly aligns the channels.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "5. We need to construct a matrix by sequential indexing of the input tensor $X$, such that for each:\n",
    "\n",
    "- Batch dimension,\n",
    "- Channel dimension,\n",
    "- Patch starting point along $x$,\n",
    "- Patch starting point along $y$,\n",
    "- And every possible position within a patch,\n",
    "\n",
    "the corresponding value from the input $X$ is stored:\n",
    "\n",
    "The resulting shape is:\n",
    "\n",
    "$$\n",
    "(batch\\_size, H\\_out, W\\_out, filter, filter, channels)\n",
    "$$\n",
    "\n",
    "Implemented as:\n",
    "\n",
    "```python\n",
    "res = X[batch_idx,\n",
    "        y_indices,  # stores y indices for all positions\n",
    "        x_indices,  # stores x indices for all positions\n",
    "        channel_idx]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "6. Last step: reshape into the desired format:\n",
    "\n",
    "$$\n",
    "(batch\\_size \\cdot H\\_out \\cdot W\\_out, filter, filter, channels)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Okay, once this is completed, the convolution operation becomes simple:\n",
    "\n",
    "- **Weights tensor shape:**\n",
    "\n",
    "$$\n",
    "(in\\_channels \\cdot filter \\cdot filter, out\\_channels)\n",
    "$$\n",
    "\n",
    "- **im2col matrix shape:**\n",
    "\n",
    "$$\n",
    "(batch\\_size \\cdot H\\_out \\cdot W\\_out, in\\_channels \\cdot filter \\cdot filter)\n",
    "$$\n",
    "\n",
    "The result (`res`) is computed and bias (`B`) is added:\n",
    "\n",
    "$$\n",
    "res + B \\quad \\text{shape: }(batch\\_size, H\\_out \\cdot W\\_out, out\\_channels)\n",
    "$$\n",
    "\n",
    "Finally, reshape the result back to:\n",
    "\n",
    "$$\n",
    "(batch\\_size, H\\_out, W\\_out, out\\_channels)\n",
    "$$\n",
    "\n",
    "This completes the forward pass.\n",
    "\n"
   ],
   "id": "498d935a40ede278"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:48:53.934952Z",
     "start_time": "2025-03-10T18:48:53.928908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def im2col_idx(x_shape, filter_size, stride):\n",
    "    \"\"\"\n",
    "    Generate indices required for extracting image patches for convolution operation.\n",
    "\n",
    "    Params:\n",
    "        x_shape: Tuple representing the shape of input tensor (batch_size, height, width, channels)\n",
    "        filter_size: Size of convolutional filter (assumed square)\n",
    "        stride: Stride size for sliding the filter\n",
    "\n",
    "    Returns:\n",
    "        batch_indices: Indices corresponding to batch dimension\n",
    "        y_indices: Indices for each patch along height dimension\n",
    "        x_indices: Indices for each patch along width dimension\n",
    "        channel_indices: Indices corresponding to channel dimension\n",
    "    \"\"\"\n",
    "    batch_size, h, w, ch = x_shape\n",
    "\n",
    "    # Corrected: y_start for height, x_start for width\n",
    "    y_start = np.arange(0, h - filter_size + 1, stride)\n",
    "    x_start = np.arange(0, w - filter_size + 1, stride)\n",
    "\n",
    "    # Corrected: meshgrid(y_start, x_start)\n",
    "    y_starts, x_starts = np.meshgrid(y_start, x_start, indexing='ij')  # [H_out, W_out]\n",
    "\n",
    "    dy, dx = np.mgrid[0:filter_size, 0:filter_size]  # [filter_size, filter_size]\n",
    "\n",
    "    y_indices = y_starts[:, :, None, None] + dy  # [H_out, W_out, k, k]\n",
    "    x_indices = x_starts[:, :, None, None] + dx  # [H_out, W_out, k, k]\n",
    "\n",
    "    # Add batch and channel dimensions\n",
    "    batch_indices = np.arange(batch_size)[:, None, None, None, None, None]  # [N, 1, 1, 1, 1, 1]\n",
    "    channel_indices = np.arange(ch)[None, None, None, None, None, :]  # [1, 1, 1, 1, 1, C]\n",
    "\n",
    "    return batch_indices, y_indices, x_indices, channel_indices\n",
    "\n",
    "\n",
    "def im2col_matrix(X, filter_size, stride):\n",
    "    \"\"\"\n",
    "    Converts batched images into a matrix format suitable for efficient GPU-based convolution operations.\n",
    "\n",
    "    Params:\n",
    "        X: Input tensor of images with shape (batch_size, height, width, in_channels)\n",
    "        filter_size: Size of convolutional filter (assumed square)\n",
    "        stride: Stride size for sliding the convolutional filter\n",
    "\n",
    "    Returns:\n",
    "        A reshaped matrix suitable for convolution with shape:\n",
    "        (batch_size * height_out * width_out, filter_size * filter_size * in_channels)\n",
    "    \"\"\"\n",
    "    batch_size, h, w, ch = X.shape\n",
    "    h_out = (h - filter_size) // stride + 1\n",
    "    w_out = (w - filter_size) // stride + 1\n",
    "\n",
    "    batch_indices, y_indices, x_indices, channel_indices = im2col_idx(X.shape, filter_size, stride)\n",
    "\n",
    "    # Expand indices for broadcasting\n",
    "    y_indices_exp = y_indices[np.newaxis, :, :, :, :, np.newaxis]  # [1, H_out, W_out, k, k, 1]\n",
    "    x_indices_exp = x_indices[np.newaxis, :, :, :, :, np.newaxis]  # [1, H_out, W_out, k, k, 1]\n",
    "\n",
    "    # Extract patches\n",
    "    patches = X[\n",
    "        batch_indices,  # [N, 1, 1, 1, 1, 1]\n",
    "        y_indices_exp,  # [1, H_out, W_out, k, k, 1]\n",
    "        x_indices_exp,  # [1, H_out, W_out, k, k, 1]\n",
    "        channel_indices # [1, 1, 1, 1, 1, C]\n",
    "    ]  # [N, H_out, W_out, k, k, C]\n",
    "\n",
    "    # Reshape to [N * H_out * W_out, k * k * C]\n",
    "    return patches.reshape(batch_size * h_out * w_out, -1)"
   ],
   "id": "127e0b1adf47f0aa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:48:54.477048Z",
     "start_time": "2025-03-10T18:48:54.473389Z"
    }
   },
   "cell_type": "code",
   "source": "a = np.arange(9).reshape((1, 3, 3, 1))",
   "id": "3b9dd135fc662b8e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"imgs/input1.png\" width=\"600px\">",
   "id": "b3bbd15f5742507d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:49:01.080408Z",
     "start_time": "2025-03-10T18:49:01.076044Z"
    }
   },
   "cell_type": "code",
   "source": "res1 = im2col_matrix(a, filter_size=2, stride=1)",
   "id": "be66ded4d09ae5b2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"imgs/output1.png\" width=\"600px\">",
   "id": "9653ef0eca37cb52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here every row is one convolutional kernel, now lets check the batching and channels.",
   "id": "3901cb83aaacbadc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:54:50.962506Z",
     "start_time": "2025-03-10T18:54:50.957923Z"
    }
   },
   "cell_type": "code",
   "source": "a = np.arange(36).reshape((2, 3, 3, 2))",
   "id": "a8e232ce21941555",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:54:51.346867Z",
     "start_time": "2025-03-10T18:54:51.340433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images = a  # Shape: (2, 2, 3, 3)\n",
    "\n",
    "# Now, images[batch, channel] gives you the 3x3 image.\n",
    "print(\"Image for batch 0, channel 0:\")\n",
    "print(images[0, 0])\n",
    "print(\"Image for batch 0, channel 1:\")\n",
    "print(images[0, 1])\n",
    "print(\"Image for batch 1, channel 0:\")\n",
    "print(images[1, 0])\n",
    "print(\"Image for batch 1, channel 1:\")\n",
    "print(images[1, 1])"
   ],
   "id": "8ac6af58ff1e9674",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for batch 0, channel 0:\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "Image for batch 0, channel 1:\n",
      "[[ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]]\n",
      "Image for batch 1, channel 0:\n",
      "[[18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "Image for batch 1, channel 1:\n",
      "[[24 25]\n",
      " [26 27]\n",
      " [28 29]]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Batch 0 Channel 0                           | Batch 0 Channel 1                           |\n",
    "|---------------------------------------------|---------------------------------------------|\n",
    "| <img src=\"imgs/input2.1.png\" width=\"400px\"> | <img src=\"imgs/input2.2.png\" width=\"400px\"> |\n",
    "\n",
    "| Batch 1 Channel 0                           | Batch 1 Channel 1                           |\n",
    "|---------------------------------------------|---------------------------------------------|\n",
    "| <img src=\"imgs/input2.3.png\" width=\"400px\"> | <img src=\"imgs/input2.4.png\" width=\"400px\"> |\n"
   ],
   "id": "75809182ccb3d40f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:54:08.941291Z",
     "start_time": "2025-03-10T18:54:08.935340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res2 = im2col_matrix(a, filter_size=2, stride=1)\n",
    "\n",
    "print(res2)"
   ],
   "id": "a75522f134d7cd06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  9  1 10  3 12  4 13]\n",
      " [ 1 10  2 11  4 13  5 14]\n",
      " [ 3 12  4 13  6 15  7 16]\n",
      " [ 4 13  5 14  7 16  8 17]\n",
      " [18 27 19 28 21 30 22 31]\n",
      " [19 28 20 29 22 31 23 32]\n",
      " [21 30 22 31 24 33 25 34]\n",
      " [22 31 23 32 25 34 26 35]]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"imgs/output2.png\" width=\"600px\">",
   "id": "da81af442efd9a30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:52:42.513374Z",
     "start_time": "2025-03-10T18:52:42.508855Z"
    }
   },
   "cell_type": "code",
   "source": "inp[0, 0, 1, 0]",
   "id": "b69321f529dff083",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fb70b73d495bb257"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
