{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convolution on GPU\n",
    "\n",
    "Modern machine learning is deeply intertwined with the concept of GPU computations. However, a GPU is not a magic button that automatically speeds up every operation. To fully harness the benefits of modern GPUs, algorithms must be carefully designed to run smoothly on these parallel architectures, leveraging concepts such as SIMD (Single Instruction, Multiple Data) along with other optimization techniques.\n",
    "\n",
    "In this notebook, I will dive into the details of how to implement a convolution operation an essential component of convolution layersâ€”specifically tailored to work efficiently on the GPU.\n",
    "\n",
    "This work will include theory, code and evaluation of the algorithm. For the implementation I will use numpy and cupy as the main tool, and also I will research on the numba tool and evaluate the ways to optimize the algorithm even further."
   ],
   "id": "2284c107c003e548"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:05:45.886881Z",
     "start_time": "2025-03-11T11:05:45.882241Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import cupy as cp\n",
    "# from numba import njit\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Basic Convolution Algorithm\n",
    "\n",
    "In the introductory lectures to the Convolutional Neural Networks, the most basic algorithm is introduced: it slides over each patch along the $i$ and $j$ axes and accumulates the result of the matrix multiplication between the input patch and the convolution kernel. In mathematical terms, for a single chanel of input $I$ and kernel $K$, the output at position $(i,j)$ is computed as:\n",
    "\n",
    "$$\n",
    "O(i,j) = \\sum_{m=0}^{k_h-1} \\sum_{n=0}^{k_w-1} I(i:i+m, j:j+n) \\cdot K(m,n)\n",
    "$$"
   ],
   "id": "7870a4f02797146d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:05:46.311706Z",
     "start_time": "2025-03-11T11:05:46.286340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def conv_forward_cpu(self, X):\n",
    "    # get shape of the input tensor\n",
    "    batch_size, height, width, in_channels = X.shape\n",
    "    # compute shape of output tensor\n",
    "    out_height = height - self.filter_size + 1 + 2 * self.padding\n",
    "    out_width = width - self.filter_size + 1 + 2 * self.padding\n",
    "    # save last input for backward pass\n",
    "    self.last_X = X\n",
    "    # create zeros tensor for result\n",
    "    result = np.zeros((batch_size, out_height, out_width, self.out_channels))\n",
    "    # reshape weights to use matrix multiplication trick\n",
    "    weights = self.W.value.reshape(self.in_channels * self.filter_size * self.filter_size, self.out_channels)\n",
    "    # iterate each pixel in output tensor\n",
    "    for y in range(out_height):\n",
    "        for x in range(out_width):\n",
    "            # take the perception widow of the output pixel\n",
    "            patch = X[:, y:y + self.filter_size, x:x + self.filter_size, :]\n",
    "            # unwrap patch to use matrix multiplication trick\n",
    "            patch_flat = patch.reshape(batch_size, self.in_channels * self.filter_size * self.filter_size)\n",
    "            # convolution operation\n",
    "            res = patch_flat @ weights + self.B.value\n",
    "            # add pixels to result tensor\n",
    "            result[:, y, x, :] = res\n",
    "    return result"
   ],
   "id": "332cb8df9d307776",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "While this approach is conceptually simple and useful to understand the idea of convolution, it has several limitations:\n",
    "\n",
    "1. **Inefficient Looping Structure:**\n",
    "   The basic algorithm uses nested loops to traverse the input chanel, resulting in $O(H \\times W \\times k_h \\times k_w)$ time complexity. This becomes computationally expensive as the input size or the kernel dimensions increase.\n",
    "\n",
    "2. **Poor Memory Access Patterns:**\n",
    "   Iterating patch-by-patch can lead to inefficient memory access, as data may not be loaded into the cache optimally. This results in significant overhead, especially when running on architectures where memory bandwidth is a critical bottleneck.\n",
    "\n",
    "3. **Limited Parallelism:**\n",
    "   GPUs thrive on parallel processing, but the naive implementation with its serial loop structure fails to exploit the inherent parallelism. The lack of vectorized operations means that the GPU's SIMD (Single Instruction, Multiple Data) capabilities remain underutilized.\n",
    "\n",
    "These challenges motivate the need for optimized approaches that reorganize computations and memory access patterns, allowing us to fully harness the power of GPU acceleration for convolution operations."
   ],
   "id": "89033405360f07e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Convolution on GPU Algorithm\n",
    "\n",
    "To start developing the algorithm, it is essential to clearly structure and understand all the input data:\n",
    "\n",
    "- **Input Tensor ($I$)**: with shape $(batch\\_size \\times in\\_channels \\times filter\\_size \\times filter\\_size)$.\n",
    "- **Weights Tensor ($W$)**: with shape $(filter\\_size \\times filter\\_size \\times in\\_channels \\times out\\_channels)$.\n",
    "- **Bias Tensor ($b$)**: with shape $(filter\\_size \\times filter\\_size \\times in\\_channels \\times out\\_channels)$.\n",
    "\n",
    "In introductory lectures on convolution operations, the most basic algorithm slides a kernel over each patch along the $i$ and $j$ axes, performing an element-wise multiplication of the patch and the weights, then summing the result to produce the output. The core issue with this basic approach is that each convolution operation is executed separately on small data patches (of size $filter\\_size \\times filter\\_size$) using implicit iteration loops.\n",
    "\n",
    "Our goal is to transform these isolated operations into a vectorized form. The approach taken here represents the entire convolution over the whole image as a single matrix multiplication. To achieve this, I introduce the `im2conv_matrix` operation, which effectively reshapes and aggregates the convolution patches into a form amenable to efficient, parallel computation on the GPU."
   ],
   "id": "7dda1b8ef9184872"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### im2conv_matrix\n",
    "\n",
    "The idea behind this operation is to transform the input tensor into a single matrix with the following shape:\n",
    "$$\n",
    "(batch\\_size \\cdot H\\_out \\cdot W\\_out \\times filter \\cdot filter \\cdot in\\_channels)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $W\\_out$ represents the total number of patches along the width.\n",
    "- $H\\_out$ represents the total number of patches along the height.\n",
    "\n",
    "In this configuration, each row corresponds to a flattened patch extracted from the input tensor, encompassing all channels.\n",
    "\n",
    "Next, we reshape the weights tensor to have the shape:\n",
    "$$\n",
    "(out\\_channels \\times filter \\cdot filter \\cdot in\\_channels)\n",
    "$$\n",
    "This reshaping organizes the filters such that each row now represents a complete set of filter weights for all input channels corresponding to a specific output channel. With this setup, we can perform the convolution operation as a single matrix multiplication, which is highly efficient on the GPU.\n",
    "\n",
    "Then the result of Convolution operation could be done as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&result = input\\_reshaped \\cdot weights^T \\\\\n",
    "&\\text{with shape } result (batch\\_size \\cdot H\\_out \\cdot W\\_out \\times out\\_channels)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "### im2conv_matrix logic\n",
    "\n",
    "Suppose input is tensor, without batching with 2 channels, then the result of the `im2conv_matrix` operation should look like:\n",
    "\n",
    "<img src=\"imgs/conv_matrix.jpg\">\n",
    "\n",
    "so every row in the `im2conv_matrix` is single conv operation.\n",
    "\n",
    "The approach to achieve that structured below:\n",
    "\n",
    "#### Approach:\n",
    "\n",
    "1. Create arrays representing starting indices of each patch along $x$ and $y$ axes:\n",
    "\n",
    "```python\n",
    "x_start = np.arange(0, h - filter, stride)\n",
    "y_start = np.arange(0, w - filter, stride)  # similarly for y-axis\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "2. Next, from these starting indices along each axis, we create a mesh-grid matrix. This allows us to identify the starting indices of each patch along both height and width dimensions for every output position:\n",
    "\n",
    "```text\n",
    "y_starts, x_starts = np.meshgrid(x_start, y_start, indexing='ij')\n",
    "y_starts: [H_out, W_out]\n",
    "x_starts: [H_out, W_out]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "3. After that, we need to add the ability to traverse each patch. Doing so allows us to get indices of each element within each patch.\n",
    "\n",
    "```python\n",
    "dy, dx = np.mgrid[0:filter, 0:filter]\n",
    "\n",
    "# indices of each element within the patch along two axes:\n",
    "y_indices = y_starts[:, :, None, None] + dy\n",
    "x_indices = x_starts[:, :, None, None] + dx\n",
    "# Resulting shape: [H_out, W_out, filter, filter]\n",
    "\n",
    "# This matrix stores (i, j) indices for each element in every convolutional patch.\n",
    "```\n",
    "\n",
    "4. Using the results from step 3, we now have the ability to get indices of any input element. The remaining step is straightforward:\n",
    "\n",
    "We want to use advanced indexing to transform the input $X$ into our desired format.\n",
    "\n",
    "```python\n",
    "batch_idx = np.arange(batch)[:, None, None, None, None, None]\n",
    "channel_idx = np.arange(channels)[None, None, :, None, None, None]\n",
    "# reshape is done so broadcasting correctly aligns the channels.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "5. We need to construct a matrix by sequential indexing of the input tensor $X$, such that for each:\n",
    "\n",
    "- Batch dimension,\n",
    "- Channel dimension,\n",
    "- Patch starting point along $x$,\n",
    "- Patch starting point along $y$,\n",
    "- And every possible position within a patch,\n",
    "\n",
    "the corresponding value from the input $X$ is stored:\n",
    "\n",
    "The resulting shape is:\n",
    "\n",
    "$$\n",
    "(batch\\_size, H\\_out, W\\_out, filter, filter, channels)\n",
    "$$\n",
    "\n",
    "Implemented as:\n",
    "\n",
    "```python\n",
    "res = X[batch_idx,\n",
    "        channel_idx,\n",
    "        y_indices,  # stores y indices for all positions\n",
    "        x_indices  # stores x indices for all positions\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "6. Last step: reshape into the desired format:\n",
    "\n",
    "$$\n",
    "(batch\\_size \\cdot H\\_out \\cdot W\\_out \\times filter \\cdot filter \\cdot channels)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Okay, once this is completed, the convolution operation becomes simple:\n",
    "\n",
    "- **Weights tensor shape:**\n",
    "\n",
    "$$\n",
    "(in\\_channels \\cdot filter \\cdot filter \\times out\\_channels)\n",
    "$$\n",
    "\n",
    "- **im2col matrix shape:**\n",
    "\n",
    "$$\n",
    "(batch\\_size \\cdot H\\_out \\cdot W\\_out \\times in\\_channels \\cdot filter \\cdot filter)\n",
    "$$\n",
    "\n",
    "The result (`res`) is computed and bias (`B`) is added:\n",
    "\n",
    "$$\n",
    "res + B \\quad \\text{shape: }(batch\\_size \\cdot H\\_out \\cdot W\\_out \\times out\\_channels)\n",
    "$$\n",
    "\n",
    "Finally, reshape the result back to:\n",
    "\n",
    "$$\n",
    "(batch\\_size, H\\_out, W\\_out, out\\_channels)\n",
    "$$\n",
    "\n",
    "This completes the forward pass.\n",
    "\n"
   ],
   "id": "498d935a40ede278"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:05:49.120635Z",
     "start_time": "2025-03-11T11:05:49.111902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def im2col_idx(x_shape, filter_size, stride):\n",
    "    \"\"\"\n",
    "    Generate indices required for extracting image patches for convolution operation.\n",
    "\n",
    "    Params:\n",
    "        x_shape: Tuple representing the shape of input tensor (batch_size, height, width, channels)\n",
    "        filter_size: Size of convolutional filter (assumed square)\n",
    "        stride: Stride size for sliding the filter\n",
    "\n",
    "    Returns:\n",
    "        batch_indices: Indices corresponding to batch dimension\n",
    "        y_indices: Indices for each patch along height dimension\n",
    "        x_indices: Indices for each patch along width dimension\n",
    "        channel_indices: Indices corresponding to channel dimension\n",
    "    \"\"\"\n",
    "    batch_size, ch, h, w = x_shape\n",
    "\n",
    "    # y_start for height patch starts, x_start for width patch starts\n",
    "    y_start = np.arange(0, h - filter_size + 1, stride)\n",
    "    x_start = np.arange(0, w - filter_size + 1, stride)\n",
    "\n",
    "    # meshgrid(y_start, x_start) for in-kernel positions\n",
    "    y_starts, x_starts = np.meshgrid(y_start, x_start, indexing='ij')  # [H_out, W_out]\n",
    "\n",
    "    dy, dx = np.mgrid[0:filter_size, 0:filter_size]  # [filter_size, filter_size]\n",
    "\n",
    "    y_indices = y_starts[:, :, None, None] + dy  # [H_out, W_out, k, k]\n",
    "    x_indices = x_starts[:, :, None, None] + dx  # [H_out, W_out, k, k]\n",
    "\n",
    "    # Add batch and channel dimensions\n",
    "    batch_indices = np.arange(batch_size)[:, None, None, None, None, None]  # [N, 1, 1, 1, 1, 1]\n",
    "    channel_indices = np.arange(ch)[None, None, None, :, None, None]  # [1, 1, 1, C, 1, 1]\n",
    "    # the order plays crucial role in proper ordering when indexing and reshaping\n",
    "\n",
    "    return batch_indices, y_indices, x_indices, channel_indices\n",
    "\n",
    "\n",
    "def im2col_matrix(X, filter_size, stride):\n",
    "    \"\"\"\n",
    "    Converts batched images into a matrix format suitable for efficient GPU-based convolution operations.\n",
    "\n",
    "    Params:\n",
    "        X: Input tensor of images with shape (batch_size, height, width, in_channels)\n",
    "        filter_size: Size of convolutional filter (assumed square)\n",
    "        stride: Stride size for sliding the convolutional filter\n",
    "\n",
    "    Returns:\n",
    "        A reshaped matrix suitable for convolution with shape:\n",
    "        (batch_size * height_out * width_out, filter_size * filter_size * in_channels)\n",
    "    \"\"\"\n",
    "    batch_size, ch,  h, w = X.shape\n",
    "    h_out = (h - filter_size) // stride + 1\n",
    "    w_out = (w - filter_size) // stride + 1\n",
    "\n",
    "    batch_indices, y_indices, x_indices, channel_indices = im2col_idx(X.shape, filter_size, stride)\n",
    "\n",
    "    # Expand indices for broadcasting\n",
    "    y_indices_exp = y_indices[np.newaxis, :, :, np.newaxis, :, :]  # [1, 1, H_out, W_out, k, k]\n",
    "    x_indices_exp = x_indices[np.newaxis, :, :, np.newaxis, :, :]  # [1, 1, H_out, W_out, k, k]\n",
    "\n",
    "    # Extract patches\n",
    "    patches = X[\n",
    "        batch_indices,  # [N, 1, 1, 1, 1, 1]\n",
    "        channel_indices, # [1, C, 1, 1, 1, 1]\n",
    "        y_indices_exp,  # [1, 1, H_out, W_out, k, k]\n",
    "        x_indices_exp  # [1, 1, H_out, W_out, k, k]\n",
    "    ]  # [N, C, H_out, W_out, k, k]\n",
    "\n",
    "    # Reshape to [N * H_out * W_out, k * k * C]\n",
    "    return patches.reshape(batch_size * h_out * w_out, filter_size * filter_size * ch)"
   ],
   "id": "127e0b1adf47f0aa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Testing\n",
    "\n",
    "Firstly test intuitive case with one batch and one chanel\n",
    "\n",
    "Perform the `im2col_matrix` on the input with filter_size = 2 and stride = 1."
   ],
   "id": "bb8f2a45de7ce8fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:05:50.212036Z",
     "start_time": "2025-03-11T11:05:50.193473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.arange(9).reshape((1, 1, 3, 3))\n",
    "\n",
    "res1 = im2col_matrix(a, filter_size=2, stride=1)"
   ],
   "id": "be66ded4d09ae5b2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Input\n",
    "\n",
    "<img src=\"imgs/input1.png\" width=\"600px\">\n",
    "\n",
    "#### Params\n",
    "- filter_size = 2\n",
    "- stride = 1\n",
    "\n",
    "#### Output\n",
    "\n",
    "<img src=\"imgs/output1.png\" width=\"600px\">"
   ],
   "id": "9653ef0eca37cb52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here every row is one convolutional kernel, now lets check the batching and channels.\n",
    "\n",
    "For the next test the input will be formed from 2 batches with 2 channels"
   ],
   "id": "3901cb83aaacbadc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = np.arange(36).reshape((2, 2, 3, 3))\n",
    "\n",
    "res2 = im2col_matrix(a, filter_size=2, stride=1)"
   ],
   "id": "a75522f134d7cd06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Input\n",
    "\n",
    "| Batch 0 Channel 0                           | Batch 0 Channel 1                           |\n",
    "|---------------------------------------------|---------------------------------------------|\n",
    "| <img src=\"imgs/input2.1.png\" width=\"400px\"> | <img src=\"imgs/input2.2.png\" width=\"400px\"> |\n",
    "\n",
    "| Batch 1 Channel 0                           | Batch 1 Channel 1                           |\n",
    "|---------------------------------------------|---------------------------------------------|\n",
    "| <img src=\"imgs/input2.3.png\" width=\"400px\"> | <img src=\"imgs/input2.4.png\" width=\"400px\"> |\n",
    "\n",
    "#### Params\n",
    "- filter_size = 2\n",
    "- stride = 1\n",
    "\n",
    "\n",
    "#### Output\n",
    "\n",
    "<img src=\"imgs/output2.png\" width=\"800px\">"
   ],
   "id": "da81af442efd9a30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Backward\n",
    "\n",
    "In this section, I will describe the part of the backward propagation process specifically related to the convolution operationâ€”particularly the computation of gradients with respect to the input tensor ($dX$).\n",
    "\n",
    "This is the most challenging aspect of this notebook, as we need to carefully implement the backward pass functionality for the input $X$.\n",
    "\n",
    "We begin with $d_{out}$, the gradient tensor received from subsequent layers, having the shape $(batch\\_size, h_{out}, w_{out}, out\\_channels)$. To simplify further computations, we first reshape this tensor into $(batch\\_size \\cdot h_{out} \\cdot w_{out}, out\\_channels)$, allowing us to handle gradients over each output channel uniformly across all batches. Given the weights tensor reshaped to $(filter \\cdot filter \\cdot in\\_channels, out\\_channels)$, we then compute the gradient with respect to the input by performing the matrix multiplication:\n",
    "\n",
    "$$\n",
    "d_{out} \\cdot weights^T\n",
    "$$\n",
    "\n",
    "This results in a gradient matrix of the familiar shape\n",
    "$$\n",
    "(batch\\_size \\cdot h_{out} \\cdot w_{out} \\times filter \\cdot filter \\cdot in\\_channels)\n",
    "$$, identical to the shape obtained previously from the `im2conv_matrix` operation. This correspondence is logical and expected.\n",
    "\n",
    "Our next step is to transform these gradient values back into the original input tensor format of shape $(batch\\_size, in\\_channels, h_{in}, w_{in})$. It's crucial to understand that some elements in the gradient matrix correspond to overlapping input patches and thus repeat. Therefore, simply reshaping the gradient matrix is insufficientâ€”we must properly accumulate gradient values at each input position.\n",
    "\n",
    "To accomplish this, we introduce a dedicated function: `col2im_backward`.\n",
    "\n",
    "---"
   ],
   "id": "db473e71a85c7bd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### col2im_backward\n",
    "\n",
    "The purpose of the `col2im_backward` function is to reverse the operation performed by `im2col`. Specifically, this function takes gradients computed with respect to the `im2col` matrix during the backward pass and transforms them back into the original spatial format of the input tensor. This process is essential to correctly accumulate gradients from overlapping patches in convolutional layers.\n",
    "\n",
    "#### Input Shape and Parameters\n",
    "\n",
    "- **`dx_patches`**: Gradient tensor with shape\n",
    "$$\n",
    "(batch\\_size \\cdot H\\_out \\cdot W\\_out \\times filter \\cdot filter \\cdot in\\_channels)\n",
    "$$\n",
    "representing gradients computed with respect to the patches extracted by `im2col`.\n",
    "\n",
    "- **`x_shape`**: Original shape of the input tensor $X$, which is:\n",
    "$$\n",
    "(batch\\_size,\\; in\\_channels,\\; h_{in},\\; w_{in})\n",
    "$$\n",
    "\n",
    "- **`filter_size`**, **`stride`**: Same convolution parameters used in the forward pass.\n",
    "\n",
    "---\n",
    "\n",
    "#### col2im_backward logic\n",
    "\n",
    "The `col2im_backward` function accumulates gradients back to their respective positions in the original input tensor. This operation is necessary due to overlapping patches: multiple patches contribute to the same input pixel, requiring a summation of their gradients.\n",
    "\n",
    "##### Approach:\n",
    "\n",
    "**1. Initialize the Gradient Tensor**\n",
    "\n",
    "Create an empty gradient tensor (`result`) initialized with zeros, matching the shape of the original input tensor.\n",
    "\n",
    "```python\n",
    "result = np.zeros((batch_size, in_channels, h_in, w_in))\n",
    "```\n",
    "\n",
    "**2. Generate Indices for Mapping Back to Original Input**\n",
    "\n",
    "Use the sames indices computed previously by the `im2col_idx` function:\n",
    "\n",
    "- **Batch indices** (`batch_indices`)\n",
    "- **Channel indices** (`channel_indices`)\n",
    "- **Height and Width indices** (`y_indices`, `x_indices`)\n",
    "\n",
    "These indices specify exactly where each element of `dx_patches` maps back into the original tensor.\n",
    "\n",
    "**3. Expand and Align Dimensions for Broadcasting**\n",
    "\n",
    "Broadcast indices to align them correctly with each other, preparing for a scatter operation. The resulting arrays all share the same shape to correspond element-wise:\n",
    "\n",
    "```python\n",
    "y_indices = y_indices[np.newaxis, :, :, np.newaxis, :, :]\n",
    "x_indices = x_indices[np.newaxis, :, :, np.newaxis, :, :]\n",
    "\n",
    "# Broadcasting indices\n",
    "batch_indices_exp = batch_indices + np.zeros_like(y_indices) + np.zeros_like(channel_indices)\n",
    "channel_indices_exp = channel_indices + np.zeros_like(y_indices) + np.zeros_like(batch_indices)\n",
    "y_indices_exp = y_indices + np.zeros_like(channel_indices) + np.zeros_like(batch_indices)\n",
    "x_indices_exp = x_indices + np.zeros_like(channel_indices) + np.zeros_like(batch_indices)\n",
    "```\n",
    "\n",
    "This ensures all indices have identical dimensions, crucial for accurately accumulating gradients.\n",
    "\n",
    "**4. Flattening the Indices and Gradient Matrix**\n",
    "\n",
    "To efficiently apply NumPyâ€™s scatter-add operation, flatten all indices and gradient arrays:\n",
    "\n",
    "```python\n",
    "batch_indices_flat = batch_indices_exp.ravel()\n",
    "channel_indices_flat = channel_indices_exp.ravel()\n",
    "y_indices_flat = y_indices_exp.ravel()\n",
    "x_indices_flat = x_indices_exp.ravel()\n",
    "dx_patches_flat = dx_patches.ravel()\n",
    "```\n",
    "\n",
    "This flattening step is critical as NumPy's `np.add.at` function operates on one-dimensional indexing arrays, this means that the length of each indexing array after broadcasting and extending will be the same and equal to total numbers of elements to add to result, then the n-th element of the values array(`dx_patches_flat[n]`) will be added to position `result[batch_indices_flat[n], channel_indices_flat[n], y_indices_flat[n], x_indices_flat[n]]`.\n",
    "\n",
    "**5. Accumulating Gradients Using `np.add.at`**\n",
    "\n",
    "Use the `np.add.at` function to accumulate gradients at the correct locations in the initialized gradient tensor:\n",
    "\n",
    "```python\n",
    "np.add.at(result,\n",
    "          (batch_indices_flat, channel_indices_flat, y_indices_flat, x_indices_flat),\n",
    "          dx_patches_flat)\n",
    "```\n",
    "\n",
    "**Why use `np.add.at`?**\n",
    "\n",
    "- The convolution operation produces overlapping patches. Thus, the gradient from one pixel location is usually distributed across multiple patches.\n",
    "- Simply assigning or adding values would overwrite data or be inefficient in terms of numpy internal logic; instead, `np.add.at` ensures gradients from overlapping patches are summed correctly, handling the repeated indices appropriately. Unlike typical buffered updates, it performs direct, unbuffered in-place additions, guaranteeing correct accumulation even with repeated indices.\n",
    "\n",
    "---"
   ],
   "id": "46763a68ffdf8968"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def col2im_backward(dx_patches, x_shape, filter_size, stride):\n",
    "    batch_size, in_ch, h_in, w_in = x_shape\n",
    "\n",
    "    # Initialize the result tensor to accumulate gradients\n",
    "    result = np.zeros((batch_size, in_ch, h_in, w_in))\n",
    "\n",
    "    # Retrieve indices used previously in im2col to map patches back to input positions\n",
    "    batch_idx, y_idx, x_idx, channel_idx = im2col_idx(x_shape, filter_size, stride)\n",
    "\n",
    "    y_idx = y_idx[np.newaxis, :, :, np.newaxis, :, :]\n",
    "    x_idx = x_idx[np.newaxis, :, :, np.newaxis, :, :]\n",
    "\n",
    "    # Expand indices dimensions for broadcasting compatibility\n",
    "    batch_idx = batch_idx + np.zeros_like(y_idx) + np.zeros_like(channel_idx)\n",
    "    channel_idx = channel_idx + np.zeros_like(y_idx) + np.zeros_like(batch_idx)\n",
    "    y_idx = y_idx + np.zeros_like(channel_idx) + np.zeros_like(batch_idx)\n",
    "    x_idx = x_idx + np.zeros_like(channel_idx) + np.zeros_like(batch_idx)\n",
    "\n",
    "    # Flatten indices and gradients to enable accumulation\n",
    "    batch_idx_flat = batch_idx.ravel()\n",
    "    y_idx_flat = y_idx.ravel()\n",
    "    x_idx_flat = x_idx.ravel()\n",
    "    channel_idx_flat = channel_idx.ravel()\n",
    "    dx_patches_flat = dx_patches.ravel()\n",
    "\n",
    "    # Accumulate gradients from dx_patches back into original input tensor positions\n",
    "    np.add.at(result, (batch_idx_flat, channel_idx_flat, y_idx_flat, x_idx_flat), dx_patches_flat)\n",
    "\n",
    "    return result"
   ],
   "id": "11ddc6b847268ac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing",
   "id": "daeed4a764ab967d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = np.ones((1, 1, 3, 3))\n",
    "\n",
    "dout = im2col_matrix(a, 2, 1)\n",
    "\n",
    "res = col2im_backward(dout, a.shape, 2, 1)"
   ],
   "id": "a0c8c13ab742396e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Input\n",
    "\n",
    "<img src=\"imgs/input3.png\" width=\"600px\">\n",
    "\n",
    "#### Output\n",
    "\n",
    "<img src=\"imgs/output3.png\" width=\"600px\">"
   ],
   "id": "257fe208b64f816a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = np.ones((2, 2, 3, 3))\n",
    "\n",
    "dout = im2col_matrix(a, 2, 1)\n",
    "\n",
    "res = col2im_backward(dout, a.shape, 2, 1)"
   ],
   "id": "317f500efe64ca77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Input\n",
    "\n",
    "<img src=\"imgs/input4.png\" width=\"600px\">\n",
    "\n",
    "- batch_size = 2\n",
    "- channels = 2\n",
    "\n",
    "\n",
    "#### Output\n",
    "\n",
    "| Batch 0 Channel 0                            | Batch 0 Channel 1                           |\n",
    "|----------------------------------------------|---------------------------------------------|\n",
    "| <img src=\"imgs/output4.1.png\" width=\"400px\"> | <img src=\"imgs/output4.1.png\" width=\"400px\"> |\n",
    "\n",
    "| Batch 1 Channel 0                           | Batch 1 Channel 1                           |\n",
    "|---------------------------------------------|---------------------------------------------|\n",
    "| <img src=\"imgs/output4.1.png\" width=\"400px\"> | <img src=\"imgs/output4.1.png\" width=\"400px\"> |"
   ],
   "id": "1259d7f91bd8ff4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now once both forward and backward part is implemented and tested, we could move to the evaluation part\n",
    "\n",
    "---\n"
   ],
   "id": "4a35c54464701377"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ConvolutionalLayer:\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 filter_size):\n",
    "        self.filter_size = filter_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.W = np.random.randn(filter_size, filter_size, in_channels, out_channels) * np.sqrt(2.0 / (filter_size * filter_size * in_channels))\n",
    "\n",
    "\n",
    "        self.B = np.zeros(out_channels)\n",
    "\n",
    "        self.last_X = None\n",
    "\n",
    "    def forward_cpu(self, X):\n",
    "        batch_size, _, in_height, in_width = X.shape\n",
    "        out_height = in_height - self.filter_size + 1\n",
    "        out_width = in_width - self.filter_size + 1\n",
    "\n",
    "        self.last_X = X\n",
    "        output = np.zeros((batch_size, self.out_channels, out_height, out_width))\n",
    "\n",
    "        # Reshape weights for matrix multiplication\n",
    "        W_reshaped = self.W.reshape(self.out_channels, -1)\n",
    "\n",
    "        for y in range(out_height):\n",
    "            for x in range(out_width):\n",
    "                # Extract patch from input (NCHW format)\n",
    "                patch = X[:, :, y:y+self.filter_size, x:x+self.filter_size]\n",
    "                # Flatten patch (batch_size, in_channels * filter_size^2)\n",
    "                patch_flat = patch.reshape(batch_size, -1)\n",
    "                # Matrix multiplication + bias\n",
    "                output[:, :, y, x] = (patch_flat @ W_reshaped.T) + self.B\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward_cpu(self, d_out):\n",
    "        X = self.last_X\n",
    "        batch_size, _, in_height, in_width = X.shape\n",
    "        _, _, out_height, out_width = d_out.shape\n",
    "\n",
    "        # Initialize gradients\n",
    "        d_X = np.zeros_like(X)\n",
    "        d_W = np.zeros_like(self.W)\n",
    "        d_B = np.zeros_like(self.B)\n",
    "\n",
    "        # Reshape weights for matrix operations\n",
    "        W_reshaped = self.W.reshape(self.out_channels, -1)\n",
    "\n",
    "        for y in range(out_height):\n",
    "            for x in range(out_width):\n",
    "                # Get current patch position\n",
    "                patch = X[:, :, y:y+self.filter_size, x:x+self.filter_size]\n",
    "                patch_flat = patch.reshape(batch_size, -1)\n",
    "\n",
    "                # Gradient for weights\n",
    "                d_W += (d_out[:, :, y, x].T @ patch_flat).reshape(self.W.shape)\n",
    "\n",
    "                # Gradient for input\n",
    "                grad = d_out[:, :, y, x] @ W_reshaped\n",
    "                d_X[:, :, y:y+self.filter_size, x:x+self.filter_size] += grad.reshape(\n",
    "                    batch_size, self.in_channels, self.filter_size, self.filter_size)\n",
    "\n",
    "        # Gradient for bias\n",
    "        d_B = d_out.sum(axis=(0, 2, 3))\n",
    "\n",
    "        return d_X, d_W, d_B\n",
    "\n",
    "    def forward_gpu(self, X):\n",
    "        self.last_X = X\n",
    "        X_gpu = cp.asarray(X)\n",
    "        batch_size, _, in_height, in_width = X_gpu.shape\n",
    "        out_height = in_height - self.filter_size + 1\n",
    "        out_width = in_width - self.filter_size + 1\n",
    "\n",
    "        # Convert weights and bias to CuPy arrays\n",
    "        W_gpu = cp.asarray(self.W.reshape(self.out_channels, -1))\n",
    "        B_gpu = cp.asarray(self.B)\n",
    "\n",
    "        # Perform im2col using CuPy\n",
    "        cols = im2col_matrix(X_gpu, self.filter_size, 1)\n",
    "\n",
    "        # Matrix multiplication and reshape\n",
    "        output = (cols @ W_gpu.T) + B_gpu\n",
    "        return output.reshape(batch_size, self.out_channels, out_height, out_width).get()\n",
    "\n",
    "    def backward_gpu(self, d_out):\n",
    "        X = self.last_X\n",
    "        d_out_gpu = d_out.reshape(-1, self.out_channels)\n",
    "        batch_size, _, in_height, in_width = X.shape\n",
    "\n",
    "        # Convert weights to CuPy array\n",
    "        W_gpu = self.W.reshape(self.out_channels, -1)\n",
    "\n",
    "        # Compute gradient for input\n",
    "        d_X = col2im_backward(d_out_gpu @ W_gpu, X.shape, self.filter_size, 1)\n",
    "\n",
    "        return d_X"
   ],
   "id": "5019b7a89ccb3cc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "43a27054a7738cab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "def benchmark_conv_layer():\n",
    "    # Warmup GPU\n",
    "    warmup_conv = ConvolutionalLayer(3, 64, 3)\n",
    "    X_warmup = cp.random.randn(1, 3, 32, 32).get()\n",
    "    _ = warmup_conv.forward_gpu(X_warmup)\n",
    "\n",
    "    # Test configurations\n",
    "    configs = [\n",
    "        {'size': (16, 3, 32, 32), 'label': '32x32'},\n",
    "        {'size': (16, 3, 256, 256), 'label': '256x256'},\n",
    "        {'size': (16, 3, 512, 512), 'label': '512x512'},\n",
    "        {'size': (16, 3, 1024, 1024), 'label': '1024x1024'},\n",
    "    ]\n",
    "\n",
    "    results = {'forward_cpu': [], 'forward_gpu': [],\n",
    "               'backward_cpu': [], 'backward_gpu': []}\n",
    "\n",
    "    for config in configs:\n",
    "        batch_size, _, h, w = config['size']\n",
    "        X = np.random.randn(*config['size']).astype(np.float32)\n",
    "\n",
    "        # Initialize layer\n",
    "        conv = ConvolutionalLayer(3, 64, 3)\n",
    "\n",
    "        # CPU benchmarks\n",
    "        # Forward\n",
    "        forward_times = []\n",
    "        for _ in range(5):\n",
    "            start = time.perf_counter()\n",
    "            output = conv.forward_cpu(X)\n",
    "            forward_times.append(time.perf_counter() - start)\n",
    "        results['forward_cpu'].append(np.median(forward_times))\n",
    "\n",
    "\n",
    "        # GPU benchmarks\n",
    "        # Forward\n",
    "        forward_gpu_times = []\n",
    "        for _ in range(5):\n",
    "            X_gpu = cp.asarray(X)\n",
    "            start = time.perf_counter()\n",
    "            output_gpu = conv.forward_gpu(X_gpu)\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "            forward_gpu_times.append(time.perf_counter() - start)\n",
    "        results['forward_gpu'].append(np.median(forward_gpu_times))\n",
    "\n",
    "        print(\"Finished \" , config['size'])\n",
    "\n",
    "\n",
    "    # Plot results\n",
    "    labels = [cfg['label'] for cfg in configs]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Forward pass plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(labels, results['forward_cpu'], 'o-', label='CPU Forward')\n",
    "    plt.plot(labels, results['forward_gpu'], 'o-', label='GPU Forward')\n",
    "    plt.title('Forward Pass Performance')\n",
    "    plt.xlabel('Input Size')\n",
    "    plt.ylabel('Time (s)')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Run the benchmark\n",
    "benchmark_conv_layer()"
   ],
   "id": "ba923fbea95c6b35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d83f8da36ad27737",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
